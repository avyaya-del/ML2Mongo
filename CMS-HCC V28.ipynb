{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f272b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "from datetime import date\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Model-wide config (equivalent to config.py)\n",
    "MODEL_VERSION = \"V28\"\n",
    "PAYMENT_YEAR = 2026\n",
    "\n",
    "DATE_ASOF = date(2026, 2, 1)\n",
    "DATE_ASOF_EDIT = DATE_ASOF\n",
    "ID_COL = \"MBI\"\n",
    "\n",
    "# TODO: paste full lists from SAS macros V2825T1M:\n",
    "\n",
    "\n",
    "DEM_VARS = [\n",
    "    \"AGEF\", \"ORIGDS\", \"DISABL\",\n",
    "    \"F0_34\",\"F35_44\",\"F45_54\",\"F55_59\",\"F60_64\",\"F65_69\",\n",
    "    \"F70_74\",\"F75_79\",\"F80_84\",\"F85_89\",\"F90_94\",\"F95_GT\",\n",
    "    \"M0_34\",\"M35_44\",\"M45_54\",\"M55_59\",\"M60_64\",\"M65_69\",\n",
    "    \"M70_74\",\"M75_79\",\"M80_84\",\"M85_89\",\"M90_94\",\"M95_GT\",\n",
    "    \"NEF0_34\",\"NEF35_44\",\"NEF45_54\",\"NEF55_59\",\"NEF60_64\",\n",
    "    \"NEF65\",\"NEF66\",\"NEF67\",\"NEF68\",\"NEF69\",\n",
    "    \"NEF70_74\",\"NEF75_79\",\"NEF80_84\",\"NEF85_89\",\"NEF90_94\",\"NEF95_GT\",\n",
    "    \"NEM0_34\",\"NEM35_44\",\"NEM45_54\",\"NEM55_59\",\"NEM60_64\",\n",
    "    \"NEM65\",\"NEM66\",\"NEM67\",\"NEM68\",\"NEM69\",\n",
    "    \"NEM70_74\",\"NEM75_79\",\"NEM80_84\",\"NEM85_89\",\"NEM90_94\",\"NEM95_GT\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "745acbe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "HCC_LIST = [\n",
    "    \"HCC1\",\"HCC2\",\"HCC6\",\"HCC17\",\"HCC18\",\"HCC19\",\"HCC20\",\"HCC21\",\"HCC22\",\"HCC23\",\n",
    "    \"HCC35\",\"HCC36\",\"HCC37\",\"HCC38\",\"HCC48\",\"HCC49\",\"HCC50\",\"HCC51\",\"HCC62\",\"HCC63\",\n",
    "    \"HCC64\",\"HCC65\",\"HCC68\",\"HCC77\",\"HCC78\",\"HCC79\",\"HCC80\",\"HCC81\",\"HCC92\",\"HCC93\",\n",
    "    \"HCC94\",\"HCC107\",\"HCC108\",\"HCC109\",\"HCC111\",\"HCC112\",\"HCC114\",\"HCC115\",\"HCC125\",\n",
    "    \"HCC126\",\"HCC127\",\"HCC135\",\"HCC136\",\"HCC137\",\"HCC138\",\"HCC139\",\"HCC151\",\"HCC152\",\n",
    "    \"HCC153\",\"HCC154\",\"HCC155\",\"HCC180\",\"HCC181\",\"HCC182\",\"HCC190\",\"HCC191\",\"HCC192\",\n",
    "    \"HCC193\",\"HCC195\",\"HCC196\",\"HCC197\",\"HCC198\",\"HCC199\",\"HCC200\",\"HCC201\",\"HCC202\",\n",
    "    \"HCC211\",\"HCC212\",\"HCC213\",\"HCC221\",\"HCC222\",\"HCC223\",\"HCC224\",\"HCC225\",\"HCC226\",\n",
    "    \"HCC227\",\"HCC228\",\"HCC229\",\"HCC238\",\"HCC248\",\"HCC249\",\"HCC253\",\"HCC254\",\"HCC263\",\n",
    "    \"HCC264\",\"HCC267\",\"HCC276\",\"HCC277\",\"HCC278\",\"HCC279\",\"HCC280\",\"HCC282\",\"HCC283\",\n",
    "    \"HCC298\",\"HCC300\",\"HCC326\",\"HCC327\",\"HCC328\",\"HCC329\",\"HCC379\",\"HCC380\",\"HCC381\",\n",
    "    \"HCC382\",\"HCC383\",\"HCC385\",\"HCC387\",\"HCC397\",\"HCC398\",\"HCC399\",\"HCC401\",\"HCC402\",\n",
    "    \"HCC405\",\"HCC409\",\"HCC454\",\"HCC463\",\n",
    "]\n",
    "\n",
    "CC_LIST = [\n",
    "    \"CC1\",\"CC2\",\"CC6\",\"CC17\",\"CC18\",\"CC19\",\"CC20\",\"CC21\",\"CC22\",\"CC23\",\n",
    "    \"CC35\",\"CC36\",\"CC37\",\"CC38\",\"CC48\",\"CC49\",\"CC50\",\"CC51\",\"CC62\",\"CC63\",\n",
    "    \"CC64\",\"CC65\",\"CC68\",\"CC77\",\"CC78\",\"CC79\",\"CC80\",\"CC81\",\"CC92\",\"CC93\",\n",
    "    \"CC94\",\"CC107\",\"CC108\",\"CC109\",\"CC111\",\"CC112\",\"CC114\",\"CC115\",\"CC125\",\n",
    "    \"CC126\",\"CC127\",\"CC135\",\"CC136\",\"CC137\",\"CC138\",\"CC139\",\"CC151\",\"CC152\",\n",
    "    \"CC153\",\"CC154\",\"CC155\",\"CC180\",\"CC181\",\"CC182\",\"CC190\",\"CC191\",\"CC192\",\n",
    "    \"CC193\",\"CC195\",\"CC196\",\"CC197\",\"CC198\",\"CC199\",\"CC200\",\"CC201\",\"CC202\",\n",
    "    \"CC211\",\"CC212\",\"CC213\",\"CC221\",\"CC222\",\"CC223\",\"CC224\",\"CC225\",\"CC226\",\n",
    "    \"CC227\",\"CC228\",\"CC229\",\"CC238\",\"CC248\",\"CC249\",\"CC253\",\"CC254\",\"CC263\",\n",
    "    \"CC264\",\"CC267\",\"CC276\",\"CC277\",\"CC278\",\"CC279\",\"CC280\",\"CC282\",\"CC283\",\n",
    "    \"CC298\",\"CC300\",\"CC326\",\"CC327\",\"CC328\",\"CC329\",\"CC379\",\"CC380\",\"CC381\",\n",
    "    \"CC382\",\"CC383\",\"CC385\",\"CC387\",\"CC397\",\"CC398\",\"CC399\",\"CC401\",\"CC402\",\n",
    "    \"CC405\",\"CC409\",\"CC454\",\"CC463\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "769c77e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalized columns: ['Diagnosis Code', 'Description', 'CMS-HCC ESRD Model Category V21', 'CMS-HCC ESRD Model Category V24', 'CMS-HCC Model Category V22', 'CMS-HCC Model Category V24', 'CMS-HCC Model Category V28', 'RxHCC Model Category V08', 'CMS-HCC ESRD Model Category V21 for 2025 Payment Year', 'CMS-HCC ESRD Model Category V24 for 2025 Payment Year', 'CMS-HCC Model Category V22 for 2025 Payment Year', 'CMS-HCC Model Category V24 for 2025 Payment Year', 'CMS-HCC Model Category V28 for 2025 Payment Year', 'RxHCC Model Category V08 for 2025 Payment Year']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(    MBI SEX        DOB  LTIMCAID  NEMCAID OREC\n",
       " 0  P001   1 1950-06-15         1        0    0\n",
       " 1  P002   2 1980-03-10         0        1    1\n",
       " 2  P003   1 1965-12-01         0        0    0,\n",
       "     MBI   DIAG\n",
       " 0  P001   E119\n",
       " 1  P001   I509\n",
       " 2  P002  C3490\n",
       " 3  P003   J449,\n",
       "    ICD10            Description CMS-HCC ESRD Model Category V21  \\\n",
       " 0  A0103      Typhoid pneumonia                             115   \n",
       " 1  A0104      Typhoid arthritis                              39   \n",
       " 2  A0105  Typhoid osteomyelitis                              39   \n",
       " 3   A021      Salmonella sepsis                               2   \n",
       " 4  A0222   Salmonella pneumonia                             115   \n",
       " \n",
       "   CMS-HCC ESRD Model Category V24 CMS-HCC Model Category V22  \\\n",
       " 0                             115                        115   \n",
       " 1                              39                         39   \n",
       " 2                              39                         39   \n",
       " 3                               2                          2   \n",
       " 4                             115                        115   \n",
       " \n",
       "   CMS-HCC Model Category V24 CMS-HCC Model Category V28  \\\n",
       " 0                        115                        NaN   \n",
       " 1                         39                         92   \n",
       " 2                         39                         92   \n",
       " 3                          2                          2   \n",
       " 4                        115                        NaN   \n",
       " \n",
       "   RxHCC Model Category V08  \\\n",
       " 0                      NaN   \n",
       " 1                      NaN   \n",
       " 2                      NaN   \n",
       " 3                      NaN   \n",
       " 4                      NaN   \n",
       " \n",
       "   CMS-HCC ESRD Model Category V21 for 2025 Payment Year  \\\n",
       " 0                                                Yes      \n",
       " 1                                                Yes      \n",
       " 2                                                Yes      \n",
       " 3                                                Yes      \n",
       " 4                                                Yes      \n",
       " \n",
       "   CMS-HCC ESRD Model Category V24 for 2025 Payment Year  \\\n",
       " 0                                                Yes      \n",
       " 1                                                Yes      \n",
       " 2                                                Yes      \n",
       " 3                                                Yes      \n",
       " 4                                                Yes      \n",
       " \n",
       "   CMS-HCC Model Category V22 for 2025 Payment Year  \\\n",
       " 0                                              Yes   \n",
       " 1                                              Yes   \n",
       " 2                                              Yes   \n",
       " 3                                              Yes   \n",
       " 4                                              Yes   \n",
       " \n",
       "   CMS-HCC Model Category V24 for 2025 Payment Year   CC  \\\n",
       " 0                                              Yes   No   \n",
       " 1                                              Yes  Yes   \n",
       " 2                                              Yes  Yes   \n",
       " 3                                              Yes  Yes   \n",
       " 4                                              Yes   No   \n",
       " \n",
       "   RxHCC Model Category V08 for 2025 Payment Year  \n",
       " 0                                             No  \n",
       " 1                                             No  \n",
       " 2                                             No  \n",
       " 3                                             No  \n",
       " 4                                             No  ,\n",
       "           model var_name   coef\n",
       " 0  COMMUNITY_NA   F65_69  0.330\n",
       " 1  COMMUNITY_NA   F70_74  0.395\n",
       " 2  COMMUNITY_NA   F75_79  0.465\n",
       " 3  COMMUNITY_NA   F80_84  0.524\n",
       " 4  COMMUNITY_NA   F85_89  0.624)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Configure input/output paths relative to notebook\n",
    "BASE = Path.cwd().parent  # notebook in notebooks/; adjust if needed\n",
    "\n",
    "person_path = BASE / \"data\" / \"person.csv\"\n",
    "diag_path   = BASE / \"data\" / \"diag.csv\"\n",
    "icd_cc_path = BASE / \"data\" / \"reference\" / \"2026 Initial ICD-10-CM Mappings.csv\"\n",
    "coef_xlsx   = BASE / \"data\" / \"reference\" / \"C2824T2N_new.xlsx\"\n",
    "\n",
    "output_dir  = BASE / \"data\" / \"output\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "output_path = output_dir / \"v28_hcc_person_scores.csv\"\n",
    "\n",
    "def load_person_csv(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, dtype={\"MBI\": str, \"SEX\": str, \"OREC\": str})\n",
    "    df[\"DOB\"] = pd.to_datetime(df[\"DOB\"])\n",
    "    return df\n",
    "\n",
    "def load_diag_csv(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, dtype={\"MBI\": str, \"DIAG\": str})\n",
    "    df[\"DIAG\"] = df[\"DIAG\"].str.strip().str.upper()\n",
    "    return df\n",
    "\n",
    "# def load_icd10_cc_map(path: Path) -> pd.DataFrame:\n",
    "#     df = pd.read_csv(path, dtype=str)\n",
    "#     df[\"ICD10\"] = df[\"ICD10\"].str.strip().str.upper()\n",
    "#     df[\"CC\"] = df[\"CC\"].astype(str).str.strip()\n",
    "#     return df\n",
    "def load_icd10_cc_map(path: Path) -> pd.DataFrame:\n",
    "    df = pd.read_csv(path, dtype=str)\n",
    "\n",
    "    # Normalize column names: strip spaces, replace newlines with spaces, collapse multiple spaces\n",
    "    new_cols = []\n",
    "    for c in df.columns:\n",
    "        c_norm = c.replace(\"\\n\", \" \").strip()\n",
    "        while \"  \" in c_norm:\n",
    "            c_norm = c_norm.replace(\"  \", \" \")\n",
    "        new_cols.append(c_norm)\n",
    "    df.columns = new_cols\n",
    "\n",
    "    print(\"Normalized columns:\", df.columns.tolist())\n",
    "\n",
    "    # Now rename the two columns we care about\n",
    "    df = df.rename(columns={\n",
    "        \"Diagnosis Code\": \"ICD10\",\n",
    "        \"CMS-HCC Model Category V28 for 2025 Payment Year\": \"CC\",\n",
    "    })\n",
    "\n",
    "    if \"ICD10\" not in df.columns or \"CC\" not in df.columns:\n",
    "        raise ValueError(\"ICD10 or CC column not found after normalization/rename\")\n",
    "\n",
    "    df[\"ICD10\"] = df[\"ICD10\"].str.strip().str.upper()\n",
    "    df[\"CC\"] = df[\"CC\"].astype(str).str.strip()\n",
    "\n",
    "    # Keep only rows with a V28 CC\n",
    "    df = df[df[\"CC\"].notna() & (df[\"CC\"] != \"\")]\n",
    "    return df\n",
    "\n",
    "#what is wrong here?\n",
    "\n",
    "# Coefficient prefix mapping – adjust if your sheet uses different prefixes\n",
    "PREFIX_TO_MODEL = {\n",
    "    \"CNA_\": \"COMMUNITY_NA\",          # Community Non-dual Aged\n",
    "    \"CND_\": \"COMMUNITY_ND\",          # Community Non-dual Disabled\n",
    "    \"CFBA_\": \"COMMUNITY_FBA\",\n",
    "    \"CFBD_\": \"COMMUNITY_FBD\",\n",
    "    \"CPBA_\": \"COMMUNITY_PBA\",\n",
    "    \"CPBD_\": \"COMMUNITY_PBD\",\n",
    "    \"INST_\": \"INSTITUTIONAL\",\n",
    "    \"NE_\":   \"NEW_ENROLLEE\",\n",
    "    \"SNE_\":  \"SNP_NEW_ENROLLEE\",\n",
    "}\n",
    "\n",
    "def load_coefficients_xlsx(path: Path) -> pd.DataFrame:\n",
    "    df_raw = pd.read_excel(path)\n",
    "    cols = {c: c.strip().lower() for c in df_raw.columns}\n",
    "    df_raw = df_raw.rename(columns=cols)\n",
    "    if \"name\" not in df_raw.columns or \"coeff\" not in df_raw.columns:\n",
    "        raise ValueError(\"Expected 'Name' and 'Coeff' columns in coefficients file.\")\n",
    "    records = []\n",
    "    for _, row in df_raw.iterrows():\n",
    "        name = str(row[\"name\"])\n",
    "        coef = float(row[\"coeff\"])\n",
    "        model = None\n",
    "        for prefix, model_id in PREFIX_TO_MODEL.items():\n",
    "            if name.startswith(prefix):\n",
    "                model = model_id\n",
    "                var_name = name[len(prefix):]\n",
    "                break\n",
    "        if model is None:\n",
    "            continue\n",
    "        records.append({\"model\": model, \"var_name\": var_name, \"coef\": coef})\n",
    "    return pd.DataFrame.from_records(records)\n",
    "\n",
    "person_df = load_person_csv(person_path)\n",
    "diag_df   = load_diag_csv(diag_path)\n",
    "icd_cc_df = load_icd10_cc_map(icd_cc_path)\n",
    "coef_df   = load_coefficients_xlsx(coef_xlsx)\n",
    "\n",
    "person_df.head(), diag_df.head(), icd_cc_df.head(), coef_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "75b188a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "Downloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   -------------------- ------------------- 1/2 [openpyxl]\n",
      "   ---------------------------------------- 2/2 [openpyxl]\n",
      "\n",
      "Successfully installed et-xmlfile-2.0.0 openpyxl-3.1.5\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: C:\\Users\\avyay\\py313_env\\Scripts\\python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a89418cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#changes from here\n",
    "\n",
    "def compute_age_vars(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    dob = pd.to_datetime(df[\"DOB\"])\n",
    "    ref = pd.to_datetime(DATE_ASOF)\n",
    "    months = (ref.year - dob.dt.year) * 12 + (ref.month - dob.dt.month)\n",
    "    months -= (ref.day < dob.dt.day).astype(int)\n",
    "    df[\"AGEF\"] = (months // 12).clip(lower=0)\n",
    "\n",
    "    ref_edit = pd.to_datetime(DATE_ASOF_EDIT)\n",
    "    months_edit = (ref_edit.year - dob.dt.year) * 12 + (ref_edit.month - dob.dt.month)\n",
    "    months_edit -= (ref_edit.day < dob.dt.day).astype(int)\n",
    "    df[\"AGEF_EDIT\"] = (months_edit // 12).clip(lower=0)\n",
    "    return df\n",
    "\n",
    "def add_age_sex_dummies(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    age = df[\"AGEF\"]\n",
    "    sex = df[\"SEX\"].astype(str)\n",
    "    orec = df[\"OREC\"].astype(str)\n",
    "\n",
    "    df[\"DISABL\"] = ((age < 65) & (orec != \"0\")).astype(int)\n",
    "    df[\"ORIGDS\"] = ((orec == \"1\") & (df[\"DISABL\"] == 0)).astype(int)\n",
    "\n",
    "    cols_24 = [\n",
    "        \"F0_34\",\"F35_44\",\"F45_54\",\"F55_59\",\"F60_64\",\"F65_69\",\n",
    "        \"F70_74\",\"F75_79\",\"F80_84\",\"F85_89\",\"F90_94\",\"F95_GT\",\n",
    "        \"M0_34\",\"M35_44\",\"M45_54\",\"M55_59\",\"M60_64\",\"M65_69\",\n",
    "        \"M70_74\",\"M75_79\",\"M80_84\",\"M85_89\",\"M90_94\",\"M95_GT\",\n",
    "    ]\n",
    "    for c in cols_24:\n",
    "        df[c] = 0\n",
    "\n",
    "    def agesex_index(row):\n",
    "        a = row[\"AGEF\"]\n",
    "        s = row[\"SEX\"]\n",
    "        if s == \"2\":\n",
    "            if 0 <= a <= 34: return 1\n",
    "            if 34 < a <= 44: return 2\n",
    "            if 44 < a <= 54: return 3\n",
    "            if 54 < a <= 59: return 4\n",
    "            if 59 < a <= 64: return 5\n",
    "            if 64 < a <= 69: return 6\n",
    "            if 69 < a <= 74: return 7\n",
    "            if 74 < a <= 79: return 8\n",
    "            if 79 < a <= 84: return 9\n",
    "            if 84 < a <= 89: return 10\n",
    "            if 89 < a <= 94: return 11\n",
    "            if a > 94:       return 12\n",
    "        if s == \"1\":\n",
    "            if 0 <= a <= 34: return 13\n",
    "            if 34 < a <= 44: return 14\n",
    "            if 44 < a <= 54: return 15\n",
    "            if 54 < a <= 59: return 16\n",
    "            if 59 < a <= 64: return 17\n",
    "            if 64 < a <= 69: return 18\n",
    "            if 69 < a <= 74: return 19\n",
    "            if 74 < a <= 79: return 20\n",
    "            if 79 < a <= 84: return 21\n",
    "            if 84 < a <= 89: return 22\n",
    "            if 89 < a <= 94: return 23\n",
    "            if a > 94:       return 24\n",
    "        return np.nan\n",
    "\n",
    "    idx = df.apply(agesex_index, axis=1)\n",
    "    for i, col in enumerate(cols_24, start=1):\n",
    "        df.loc[idx == i, col] = 1\n",
    "\n",
    "    # NEF*/NEM* – implement NE_AGESEX logic from AGESEXV2.TXT here (straight copy of CASE rules). [file:35]\n",
    "    # For now, initialize to 0 so code runs; you can fill exact rules later.\n",
    "#     ne_cols = [\n",
    "#         \"NEF0_34\",\"NEF35_44\",\"NEF45_54\",\"NEF55_59\",\"NEF60_64\",\n",
    "#         \"NEF65\",\"NEF66\",\"NEF67\",\"NEF68\",\"NEF69\",\n",
    "#         \"NEF70_74\",\"NEF75_79\",\"NEF80_84\",\"NEF85_89\",\"NEF90_94\",\"NEF95_GT\",\n",
    "#         \"NEM0_34\",\"NEM35_44\",\"NEM45_54\",\"NEM55_59\",\"NEM60_64\",\n",
    "#         \"NEM65\",\"NEM66\",\"NEM67\",\"NEM68\",\"NEM69\",\n",
    "#         \"NEM70_74\",\"NEM75_79\",\"NEM80_84\",\"NEM85_89\",\"NEM90_94\",\"NEM95_GT\",\n",
    "#     ]\n",
    "#     for c in ne_cols:\n",
    "#         df[c] = 0\n",
    "\n",
    "#     return df\n",
    "        # --- New Enrollee age/sex dummies (NEF*/NEM*) --- [file:35]\n",
    "    ne_cols = [\n",
    "        \"NEF0_34\",\"NEF35_44\",\"NEF45_54\",\"NEF55_59\",\"NEF60_64\",\n",
    "        \"NEF65\",\"NEF66\",\"NEF67\",\"NEF68\",\"NEF69\",\n",
    "        \"NEF70_74\",\"NEF75_79\",\"NEF80_84\",\"NEF85_89\",\"NEF90_94\",\"NEF95_GT\",\n",
    "        \"NEM0_34\",\"NEM35_44\",\"NEM45_54\",\"NEM55_59\",\"NEM60_64\",\n",
    "        \"NEM65\",\"NEM66\",\"NEM67\",\"NEM68\",\"NEM69\",\n",
    "        \"NEM70_74\",\"NEM75_79\",\"NEM80_84\",\"NEM85_89\",\"NEM90_94\",\"NEM95_GT\",\n",
    "    ]\n",
    "    for c in ne_cols:\n",
    "        df[c] = 0\n",
    "\n",
    "    def ne_agesex_index(row):\n",
    "        a = row[\"AGEF\"]\n",
    "        s = row[\"SEX\"]\n",
    "        o = row[\"OREC\"]\n",
    "        # Female (SEX='2') [file:35]\n",
    "        if s == \"2\":\n",
    "            if 0 <= a <= 34: return 1   # NEF0_34\n",
    "            if 34 < a <= 44: return 2   # NEF35_44\n",
    "            if 44 < a <= 54: return 3   # NEF45_54\n",
    "            if 54 < a <= 59: return 4   # NEF55_59\n",
    "            if 59 < a <= 63: return 5   # NEF60_64\n",
    "            if a == 64 and o != \"0\": return 5   # disabled 64 -> 60-64 bucket\n",
    "            if a == 64 and o == \"0\": return 6   # old-age 64 -> 65 bucket\n",
    "            if a == 65: return 6       # NEF65\n",
    "            if a == 66: return 7       # NEF66\n",
    "            if a == 67: return 8       # NEF67\n",
    "            if a == 68: return 9       # NEF68\n",
    "            if a == 69: return 10      # NEF69\n",
    "            if 69 < a <= 74: return 11 # NEF70_74\n",
    "            if 74 < a <= 79: return 12 # NEF75_79\n",
    "            if 79 < a <= 84: return 13 # NEF80_84\n",
    "            if 84 < a <= 89: return 14 # NEF85_89\n",
    "            if 89 < a <= 94: return 15 # NEF90_94\n",
    "            if a > 94:       return 16 # NEF95_GT\n",
    "        # Male (SEX='1') [file:35]\n",
    "        if s == \"1\":\n",
    "            if 0 <= a <= 34: return 17  # NEM0_34\n",
    "            if 34 < a <= 44: return 18  # NEM35_44\n",
    "            if 44 < a <= 54: return 19  # NEM45_54\n",
    "            if 54 < a <= 59: return 20  # NEM55_59\n",
    "            if 59 < a <= 63: return 21  # NEM60_64\n",
    "            if a == 64 and o != \"0\": return 21  # disabled 64 -> 60-64 bucket\n",
    "            if a == 64 and o == \"0\":  return 22 # old-age 64 -> 65 bucket\n",
    "            if a == 65: return 22     # NEM65\n",
    "            if a == 66: return 23     # NEM66\n",
    "            if a == 67: return 24     # NEM67\n",
    "            if a == 68: return 25     # NEM68\n",
    "            if a == 69: return 26     # NEM69\n",
    "            if 69 < a <= 74: return 27 # NEM70_74\n",
    "            if 74 < a <= 79: return 28 # NEM75_79\n",
    "            if 79 < a <= 84: return 29 # NEM80_84\n",
    "            if 84 < a <= 89: return 30 # NEM85_89\n",
    "            if 89 < a <= 94: return 31 # NEM90_94\n",
    "            if a > 94:       return 32 # NEM95_GT\n",
    "        return np.nan\n",
    "\n",
    "    ne_idx = df.apply(ne_agesex_index, axis=1)\n",
    "\n",
    "    # Map index 1..16 to NEF*, 17..32 to NEM* exactly like NECELL array in SAS [file:35]\n",
    "    ne_order = [\n",
    "        \"NEF0_34\",\"NEF35_44\",\"NEF45_54\",\"NEF55_59\",\"NEF60_64\",\n",
    "        \"NEF65\",\"NEF66\",\"NEF67\",\"NEF68\",\"NEF69\",\n",
    "        \"NEF70_74\",\"NEF75_79\",\"NEF80_84\",\"NEF85_89\",\"NEF90_94\",\"NEF95_GT\",\n",
    "        \"NEM0_34\",\"NEM35_44\",\"NEM45_54\",\"NEM55_59\",\"NEM60_64\",\n",
    "        \"NEM65\",\"NEM66\",\"NEM67\",\"NEM68\",\"NEM69\",\n",
    "        \"NEM70_74\",\"NEM75_79\",\"NEM80_84\",\"NEM85_89\",\"NEM90_94\",\"NEM95_GT\",\n",
    "    ]\n",
    "    for i, col in enumerate(ne_order, start=1):\n",
    "        df.loc[ne_idx == i, col] = 1\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0a4d9650",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_cc_flags(person_df, diag_df, icd_cc_df) -> pd.DataFrame:\n",
    "    d = diag_df.merge(icd_cc_df, left_on=\"DIAG\", right_on=\"ICD10\", how=\"left\")\n",
    "    d = d[d[\"CC\"].notna()]\n",
    "    d[\"flag\"] = 1\n",
    "    cc_wide = (\n",
    "        d.pivot_table(\n",
    "            index=ID_COL,\n",
    "            columns=\"CC\",\n",
    "            values=\"flag\",\n",
    "            aggfunc=\"max\",\n",
    "            fill_value=0,\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "    cc_wide.columns.name = None\n",
    "\n",
    "    # rename numeric CC codes (e.g. \"92\") to \"CC92\"\n",
    "    rename = {}\n",
    "    for col in cc_wide.columns:\n",
    "        if col != ID_COL and not col.startswith(\"CC\"):\n",
    "            rename[col] = f\"CC{col}\"\n",
    "    cc_wide = cc_wide.rename(columns=rename)\n",
    "\n",
    "    for cc_var in CC_LIST:\n",
    "        if cc_var not in cc_wide.columns:\n",
    "            cc_wide[cc_var] = 0\n",
    "\n",
    "    return cc_wide\n",
    "\n",
    "# def apply_hierarchy(person_df, cc_flags_df) -> pd.DataFrame:\n",
    "#     df = person_df.merge(cc_flags_df, on=ID_COL, how=\"left\").fillna(0)\n",
    "\n",
    "#     # Copy CC -> HCC assuming HCC_LIST and CC_LIST aligned by index [file:36][file:31]\n",
    "#     for cc_var, hcc_var in zip(CC_LIST, HCC_LIST):\n",
    "#         df[hcc_var] = df[cc_var]\n",
    "\n",
    "#     def set0(df, cc_num, hier_nums):\n",
    "#         cc_col = f\"HCC{cc_num}\"\n",
    "#         if cc_col not in df.columns:\n",
    "#             return df\n",
    "#         mask = df[cc_col] == 1\n",
    "#         for h in hier_nums:\n",
    "#             h_col = f\"HCC{h}\"\n",
    "#             if h_col in df.columns:\n",
    "#                 df.loc[mask, h_col] = 0\n",
    "#         return df\n",
    "\n",
    "#     # Paste all SET0 lines from V28115H1.TXT here. Example: [file:36]\n",
    "#     df = set0(df, 17, [18, 19, 20, 21, 22, 23])\n",
    "#     df = set0(df, 18, [19, 20, 21, 22, 23])\n",
    "#     df = set0(df, 19, [20, 21, 22, 23])\n",
    "#     df = set0(df, 20, [21, 22, 23])\n",
    "#     df = set0(df, 21, [22, 23])\n",
    "#     df = set0(df, 22, [23])\n",
    "#     # ...continue for all Diabetes, Liver, GI, Heart, Lung, etc hierarchies in V28115H1.TXT\n",
    "\n",
    "#     return df\n",
    "def apply_hierarchy(person_df, cc_flags_df) -> pd.DataFrame:\n",
    "    df = person_df.merge(cc_flags_df, on=ID_COL, how=\"left\").fillna(0)\n",
    "\n",
    "    # Copy CC -> HCC assuming HCC_LIST and CC_LIST aligned by index [file:36][file:38]\n",
    "    for cc_var, hcc_var in zip(CC_LIST, HCC_LIST):\n",
    "        df[hcc_var] = df[cc_var]\n",
    "\n",
    "    def set0(df, cc_num, hier_nums):\n",
    "        cc_col = f\"HCC{cc_num}\"\n",
    "        if cc_col not in df.columns:\n",
    "            return df\n",
    "        mask = df[cc_col] == 1\n",
    "        for h in hier_nums:\n",
    "            h_col = f\"HCC{h}\"\n",
    "            if h_col in df.columns:\n",
    "                df.loc[mask, h_col] = 0\n",
    "        return df\n",
    "\n",
    "    # --- Hierarchies from V28115H1.TXT --- [file:36]\n",
    "\n",
    "    # Neoplasm\n",
    "    df = set0(df, 17, [18, 19, 20, 21, 22, 23])\n",
    "    df = set0(df, 18, [19, 20, 21, 22, 23])\n",
    "    df = set0(df, 19, [20, 21, 22, 23])\n",
    "    df = set0(df, 20, [21, 22, 23])\n",
    "    df = set0(df, 21, [22, 23])\n",
    "    df = set0(df, 22, [23])\n",
    "\n",
    "    # Diabetes\n",
    "    df = set0(df, 35, [36, 37, 38])\n",
    "    df = set0(df, 36, [37, 38])\n",
    "    df = set0(df, 37, [38])\n",
    "\n",
    "    # Liver\n",
    "    df = set0(df, 62, [63, 64, 65, 68])\n",
    "    df = set0(df, 63, [64, 65, 68, 202])\n",
    "    df = set0(df, 64, [65, 68])\n",
    "\n",
    "    # GI\n",
    "    df = set0(df, 77, [78, 80, 81])\n",
    "    df = set0(df, 80, [81])\n",
    "\n",
    "    # MSK\n",
    "    df = set0(df, 93, [94])\n",
    "\n",
    "    # Blood\n",
    "    df = set0(df, 107, [108])\n",
    "    df = set0(df, 111, [112])\n",
    "    df = set0(df, 114, [115])\n",
    "\n",
    "    # Cognitive\n",
    "    df = set0(df, 125, [126, 127])\n",
    "    df = set0(df, 126, [127])\n",
    "\n",
    "    # Substance Use Disorder (SUD)\n",
    "    df = set0(df, 135, [136, 137, 138, 139])\n",
    "    df = set0(df, 136, [137, 138, 139])\n",
    "    df = set0(df, 137, [138, 139])\n",
    "    df = set0(df, 138, [139])\n",
    "\n",
    "    # Psychiatric\n",
    "    df = set0(df, 151, [152, 153, 154, 155])\n",
    "    df = set0(df, 152, [153, 154, 155])\n",
    "    df = set0(df, 153, [154, 155])\n",
    "    df = set0(df, 154, [155])\n",
    "\n",
    "    # Spinal\n",
    "    df = set0(df, 180, [181, 182, 253, 254])\n",
    "    df = set0(df, 181, [182, 254])\n",
    "\n",
    "    # Neuro\n",
    "    df = set0(df, 191, [180, 181, 182, 192, 253, 254])\n",
    "    df = set0(df, 192, [180, 181, 182, 253, 254])\n",
    "    df = set0(df, 195, [196])\n",
    "\n",
    "    # Arrest\n",
    "    df = set0(df, 211, [212, 213])\n",
    "    df = set0(df, 212, [213])\n",
    "\n",
    "    # Heart\n",
    "    df = set0(df, 221, [222, 223, 224, 225, 226, 227])\n",
    "    df = set0(df, 222, [223, 224, 225, 226, 227])\n",
    "    df = set0(df, 223, [224, 225, 226, 227])\n",
    "    df = set0(df, 224, [225, 226, 227])\n",
    "    df = set0(df, 225, [226, 227])\n",
    "    df = set0(df, 226, [227])\n",
    "    df = set0(df, 228, [229])\n",
    "\n",
    "    # CVD\n",
    "    df = set0(df, 248, [249])\n",
    "    df = set0(df, 253, [254])\n",
    "\n",
    "    # Vascular\n",
    "    df = set0(df, 263, [264, 383, 409])\n",
    "\n",
    "    # Lung\n",
    "    df = set0(df, 276, [277, 278, 279, 280])\n",
    "    df = set0(df, 277, [278, 279, 280])\n",
    "    df = set0(df, 278, [279, 280])\n",
    "    df = set0(df, 279, [280])\n",
    "    df = set0(df, 282, [283])\n",
    "\n",
    "    # Kidney\n",
    "    df = set0(df, 326, [327, 328, 329])\n",
    "    df = set0(df, 327, [328, 329])\n",
    "    df = set0(df, 328, [329])\n",
    "\n",
    "    # Skin\n",
    "    df = set0(df, 379, [380, 381, 382, 383])\n",
    "    df = set0(df, 380, [381, 382, 383])\n",
    "    df = set0(df, 381, [382, 383])\n",
    "    df = set0(df, 382, [383])\n",
    "\n",
    "    # Injury\n",
    "    df = set0(df, 397, [202, 398, 399])\n",
    "    df = set0(df, 398, [202, 399])\n",
    "    df = set0(df, 405, [409])\n",
    "\n",
    "    return df\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6b1165cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: paste these from V2825T1M.TXT [file:31]\n",
    "COMM_REGA = [\n",
    "    # &AGESEXVA\n",
    "    \"F65_69\",\n",
    "    \"F70_74\", \"F75_79\", \"F80_84\", \"F85_89\", \"F90_94\", \"F95_GT\",\n",
    "    \"M65_69\",\n",
    "    \"M70_74\", \"M75_79\", \"M80_84\", \"M85_89\", \"M90_94\", \"M95_GT\",\n",
    "    # &ORIG_INT\n",
    "    \"OriginallyDisabled_Female\", \"OriginallyDisabled_Male\",\n",
    "    # &HCClist  (HCCV28_list115)\n",
    "    *HCC_LIST,\n",
    "    # &INTERRACC_VARSA\n",
    "    \"DIABETES_HF_V28\",\n",
    "    \"HF_CHR_LUNG_V28\",\n",
    "    \"HF_KIDNEY_V28\",\n",
    "    \"CHR_LUNG_CARD_RESP_FAIL_V28\",\n",
    "    \"HF_HCC238_V28\",\n",
    "    # &ADDZ\n",
    "    \"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"D10P\",\n",
    "]\n",
    "\n",
    "COMM_REGD = [\n",
    "    # &AGESEXVD\n",
    "    \"F0_34\", \"F35_44\", \"F45_54\", \"F55_59\", \"F60_64\",\n",
    "    \"M0_34\", \"M35_44\", \"M45_54\", \"M55_59\", \"M60_64\",\n",
    "    # &HCClist\n",
    "    *HCC_LIST,\n",
    "    # &INTERRACC_VARSD\n",
    "    \"DIABETES_HF_V28\",\n",
    "    \"HF_CHR_LUNG_V28\",\n",
    "    \"HF_KIDNEY_V28\",\n",
    "    \"CHR_LUNG_CARD_RESP_FAIL_V28\",\n",
    "    \"HF_HCC238_V28\",\n",
    "    \"gSubUseDisorder_gPsych_V28\",\n",
    "    # &ADDZ\n",
    "    \"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"D10P\",\n",
    "]\n",
    "\n",
    "INST_REG = [\n",
    "    # &AGESEXV\n",
    "    \"F0_34\", \"F35_44\", \"F45_54\", \"F55_59\", \"F60_64\", \"F65_69\",\n",
    "    \"F70_74\", \"F75_79\", \"F80_84\", \"F85_89\", \"F90_94\", \"F95_GT\",\n",
    "    \"M0_34\", \"M35_44\", \"M45_54\", \"M55_59\", \"M60_64\", \"M65_69\",\n",
    "    \"M70_74\", \"M75_79\", \"M80_84\", \"M85_89\", \"M90_94\", \"M95_GT\",\n",
    "    # LTIMCAID ORIGDS\n",
    "    \"LTIMCAID\", \"ORIGDS\",\n",
    "    # &HCClist\n",
    "    *HCC_LIST,\n",
    "    # &INTERRACI_VARS\n",
    "    \"DIABETES_HF_V28\",\n",
    "    \"HF_CHR_LUNG_V28\",\n",
    "    \"HF_KIDNEY_V28\",\n",
    "    \"CHR_LUNG_CARD_RESP_FAIL_V28\",\n",
    "    \"DISABLED_CANCER_V28\",\n",
    "    \"DISABLED_NEURO_V28\",\n",
    "    \"DISABLED_HF_V28\",\n",
    "    \"DISABLED_CHR_LUNG_V28\",\n",
    "    \"DISABLED_ULCER_V28\",\n",
    "    # &ADDZ\n",
    "    \"D1\", \"D2\", \"D3\", \"D4\", \"D5\", \"D6\", \"D7\", \"D8\", \"D9\", \"D10P\",\n",
    "]\n",
    "\n",
    "NE_REG = [\n",
    "   \"NMCAID_NORIGDIS_NEF0_34\",  \"NMCAID_NORIGDIS_NEF35_44\",\n",
    "   \"NMCAID_NORIGDIS_NEF45_54\", \"NMCAID_NORIGDIS_NEF55_59\",\n",
    "   \"NMCAID_NORIGDIS_NEF60_64\", \"NMCAID_NORIGDIS_NEF65\",\n",
    "   \"NMCAID_NORIGDIS_NEF66\",    \"NMCAID_NORIGDIS_NEF67\",\n",
    "   \"NMCAID_NORIGDIS_NEF68\",    \"NMCAID_NORIGDIS_NEF69\",\n",
    "   \"NMCAID_NORIGDIS_NEF70_74\", \"NMCAID_NORIGDIS_NEF75_79\",\n",
    "   \"NMCAID_NORIGDIS_NEF80_84\", \"NMCAID_NORIGDIS_NEF85_89\",\n",
    "   \"NMCAID_NORIGDIS_NEF90_94\", \"NMCAID_NORIGDIS_NEF95_GT\",\n",
    "\n",
    "   \"NMCAID_NORIGDIS_NEM0_34\",  \"NMCAID_NORIGDIS_NEM35_44\",\n",
    "   \"NMCAID_NORIGDIS_NEM45_54\", \"NMCAID_NORIGDIS_NEM55_59\",\n",
    "   \"NMCAID_NORIGDIS_NEM60_64\", \"NMCAID_NORIGDIS_NEM65\",\n",
    "   \"NMCAID_NORIGDIS_NEM66\",    \"NMCAID_NORIGDIS_NEM67\",\n",
    "   \"NMCAID_NORIGDIS_NEM68\",    \"NMCAID_NORIGDIS_NEM69\",\n",
    "   \"NMCAID_NORIGDIS_NEM70_74\", \"NMCAID_NORIGDIS_NEM75_79\",\n",
    "   \"NMCAID_NORIGDIS_NEM80_84\", \"NMCAID_NORIGDIS_NEM85_89\",\n",
    "   \"NMCAID_NORIGDIS_NEM90_94\", \"NMCAID_NORIGDIS_NEM95_GT\",\n",
    "\n",
    "   \"MCAID_NORIGDIS_NEF0_34\",   \"MCAID_NORIGDIS_NEF35_44\",\n",
    "   \"MCAID_NORIGDIS_NEF45_54\",  \"MCAID_NORIGDIS_NEF55_59\",\n",
    "   \"MCAID_NORIGDIS_NEF60_64\",  \"MCAID_NORIGDIS_NEF65\",\n",
    "   \"MCAID_NORIGDIS_NEF66\",     \"MCAID_NORIGDIS_NEF67\",\n",
    "   \"MCAID_NORIGDIS_NEF68\",     \"MCAID_NORIGDIS_NEF69\",\n",
    "   \"MCAID_NORIGDIS_NEF70_74\",  \"MCAID_NORIGDIS_NEF75_79\",\n",
    "   \"MCAID_NORIGDIS_NEF80_84\",  \"MCAID_NORIGDIS_NEF85_89\",\n",
    "   \"MCAID_NORIGDIS_NEF90_94\",  \"MCAID_NORIGDIS_NEF95_GT\",\n",
    "\n",
    "   \"MCAID_NORIGDIS_NEM0_34\",   \"MCAID_NORIGDIS_NEM35_44\",\n",
    "   \"MCAID_NORIGDIS_NEM45_54\",  \"MCAID_NORIGDIS_NEM55_59\",\n",
    "   \"MCAID_NORIGDIS_NEM60_64\",  \"MCAID_NORIGDIS_NEM65\",\n",
    "   \"MCAID_NORIGDIS_NEM66\",     \"MCAID_NORIGDIS_NEM67\",\n",
    "   \"MCAID_NORIGDIS_NEM68\",     \"MCAID_NORIGDIS_NEM69\",\n",
    "   \"MCAID_NORIGDIS_NEM70_74\",  \"MCAID_NORIGDIS_NEM75_79\",\n",
    "   \"MCAID_NORIGDIS_NEM80_84\",  \"MCAID_NORIGDIS_NEM85_89\",\n",
    "   \"MCAID_NORIGDIS_NEM90_94\",  \"MCAID_NORIGDIS_NEM95_GT\",\n",
    "\n",
    "   \"NMCAID_ORIGDIS_NEF65\",     \"NMCAID_ORIGDIS_NEF66\",\n",
    "   \"NMCAID_ORIGDIS_NEF67\",     \"NMCAID_ORIGDIS_NEF68\",\n",
    "   \"NMCAID_ORIGDIS_NEF69\",     \"NMCAID_ORIGDIS_NEF70_74\",\n",
    "   \"NMCAID_ORIGDIS_NEF75_79\",  \"NMCAID_ORIGDIS_NEF80_84\",\n",
    "   \"NMCAID_ORIGDIS_NEF85_89\",  \"NMCAID_ORIGDIS_NEF90_94\",\n",
    "   \"NMCAID_ORIGDIS_NEF95_GT\",\n",
    "\n",
    "   \"NMCAID_ORIGDIS_NEM65\",     \"NMCAID_ORIGDIS_NEM66\",\n",
    "   \"NMCAID_ORIGDIS_NEM67\",     \"NMCAID_ORIGDIS_NEM68\",\n",
    "   \"NMCAID_ORIGDIS_NEM69\",     \"NMCAID_ORIGDIS_NEM70_74\",\n",
    "   \"NMCAID_ORIGDIS_NEM75_79\",  \"NMCAID_ORIGDIS_NEM80_84\",\n",
    "   \"NMCAID_ORIGDIS_NEM85_89\",  \"NMCAID_ORIGDIS_NEM90_94\",\n",
    "   \"NMCAID_ORIGDIS_NEM95_GT\",\n",
    "\n",
    "   \"MCAID_ORIGDIS_NEF65\",      \"MCAID_ORIGDIS_NEF66\",\n",
    "   \"MCAID_ORIGDIS_NEF67\",      \"MCAID_ORIGDIS_NEF68\",\n",
    "   \"MCAID_ORIGDIS_NEF69\",      \"MCAID_ORIGDIS_NEF70_74\",\n",
    "   \"MCAID_ORIGDIS_NEF75_79\",   \"MCAID_ORIGDIS_NEF80_84\",\n",
    "   \"MCAID_ORIGDIS_NEF85_89\",   \"MCAID_ORIGDIS_NEF90_94\",\n",
    "   \"MCAID_ORIGDIS_NEF95_GT\",\n",
    "\n",
    "   \"MCAID_ORIGDIS_NEM65\",      \"MCAID_ORIGDIS_NEM66\",\n",
    "   \"MCAID_ORIGDIS_NEM67\",      \"MCAID_ORIGDIS_NEM68\",\n",
    "   \"MCAID_ORIGDIS_NEM69\",      \"MCAID_ORIGDIS_NEM70_74\",\n",
    "   \"MCAID_ORIGDIS_NEM75_79\",   \"MCAID_ORIGDIS_NEM80_84\",\n",
    "   \"MCAID_ORIGDIS_NEM85_89\",   \"MCAID_ORIGDIS_NEM90_94\",\n",
    "   \"MCAID_ORIGDIS_NEM95_GT\",\n",
    "]\n",
    "\n",
    "\n",
    "def score_linear(df: pd.DataFrame, var_list, coef_series) -> pd.Series:\n",
    "    missing = [v for v in var_list if v not in df.columns]\n",
    "    for v in missing:\n",
    "        df[v] = 0.0\n",
    "    aligned_coefs = coef_series.reindex(var_list).fillna(0.0)\n",
    "    return (df[var_list] * aligned_coefs.values).sum(axis=1)\n",
    "\n",
    "def compute_all_scores(df: pd.DataFrame, coef_df: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = df.copy()\n",
    "    configs = [\n",
    "        (\"SCORE_COMMUNITY_NA\",  \"COMMUNITY_NA\",  COMM_REGA),\n",
    "        (\"SCORE_COMMUNITY_ND\",  \"COMMUNITY_ND\",  COMM_REGD),\n",
    "        (\"SCORE_COMMUNITY_FBA\", \"COMMUNITY_FBA\", COMM_REGA),\n",
    "        (\"SCORE_COMMUNITY_FBD\", \"COMMUNITY_FBD\", COMM_REGD),\n",
    "        (\"SCORE_COMMUNITY_PBA\", \"COMMUNITY_PBA\", COMM_REGA),\n",
    "        (\"SCORE_COMMUNITY_PBD\", \"COMMUNITY_PBD\", COMM_REGD),\n",
    "        (\"SCORE_INSTITUTIONAL\", \"INSTITUTIONAL\", INST_REG),\n",
    "        (\"SCORE_NEW_ENROLLEE\",  \"NEW_ENROLLEE\",  NE_REG),\n",
    "        (\"SCORE_SNP_NEW_ENROLLEE\", \"SNP_NEW_ENROLLEE\", NE_REG),\n",
    "    ]\n",
    "\n",
    "    for out_var, model_name, var_list in configs:\n",
    "        coef_series = (\n",
    "            coef_df[coef_df[\"model\"] == model_name]\n",
    "            .set_index(\"var_name\")[\"coef\"]\n",
    "        )\n",
    "        df[out_var] = score_linear(df, var_list, coef_series)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ea5afd21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape after scoring: (3, 437)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:26: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  cc_wide[cc_var] = 0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3706421954.py:63: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[hcc_var] = df[cc_var]\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:133: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[v] = 0.0\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out_var] = score_linear(df, var_list, coef_series)\n",
      "C:\\Users\\avyay\\AppData\\Local\\Temp\\ipykernel_1260\\3197832736.py:156: PerformanceWarning: DataFrame is highly fragmented.  This is usually the result of calling `frame.insert` many times, which has poor performance.  Consider joining all columns at once using pd.concat(axis=1) instead. To get a de-fragmented frame, use `newframe = frame.copy()`\n",
      "  df[out_var] = score_linear(df, var_list, coef_series)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBI</th>\n",
       "      <th>SEX</th>\n",
       "      <th>DOB</th>\n",
       "      <th>LTIMCAID</th>\n",
       "      <th>NEMCAID</th>\n",
       "      <th>OREC</th>\n",
       "      <th>AGEF</th>\n",
       "      <th>AGEF_EDIT</th>\n",
       "      <th>DISABL</th>\n",
       "      <th>ORIGDS</th>\n",
       "      <th>...</th>\n",
       "      <th>MCAID_ORIGDIS_NEM68</th>\n",
       "      <th>MCAID_ORIGDIS_NEM69</th>\n",
       "      <th>MCAID_ORIGDIS_NEM70_74</th>\n",
       "      <th>MCAID_ORIGDIS_NEM75_79</th>\n",
       "      <th>MCAID_ORIGDIS_NEM80_84</th>\n",
       "      <th>MCAID_ORIGDIS_NEM85_89</th>\n",
       "      <th>MCAID_ORIGDIS_NEM90_94</th>\n",
       "      <th>MCAID_ORIGDIS_NEM95_GT</th>\n",
       "      <th>SCORE_NEW_ENROLLEE</th>\n",
       "      <th>SCORE_SNP_NEW_ENROLLEE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>1</td>\n",
       "      <td>1950-06-15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>2</td>\n",
       "      <td>1980-03-10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>1</td>\n",
       "      <td>1965-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MBI SEX        DOB  LTIMCAID  NEMCAID OREC  AGEF  AGEF_EDIT  DISABL  \\\n",
       "0  P001   1 1950-06-15         1        0    0    75         75       0   \n",
       "1  P002   2 1980-03-10         0        1    1    45         45       1   \n",
       "2  P003   1 1965-12-01         0        0    0    60         60       0   \n",
       "\n",
       "   ORIGDS  ...  MCAID_ORIGDIS_NEM68  MCAID_ORIGDIS_NEM69  \\\n",
       "0       0  ...                  0.0                  0.0   \n",
       "1       0  ...                  0.0                  0.0   \n",
       "2       0  ...                  0.0                  0.0   \n",
       "\n",
       "   MCAID_ORIGDIS_NEM70_74  MCAID_ORIGDIS_NEM75_79  MCAID_ORIGDIS_NEM80_84  \\\n",
       "0                     0.0                     0.0                     0.0   \n",
       "1                     0.0                     0.0                     0.0   \n",
       "2                     0.0                     0.0                     0.0   \n",
       "\n",
       "   MCAID_ORIGDIS_NEM85_89  MCAID_ORIGDIS_NEM90_94  MCAID_ORIGDIS_NEM95_GT  \\\n",
       "0                     0.0                     0.0                     0.0   \n",
       "1                     0.0                     0.0                     0.0   \n",
       "2                     0.0                     0.0                     0.0   \n",
       "\n",
       "   SCORE_NEW_ENROLLEE  SCORE_SNP_NEW_ENROLLEE  \n",
       "0                 0.0                     0.0  \n",
       "1                 0.0                     0.0  \n",
       "2                 0.0                     0.0  \n",
       "\n",
       "[3 rows x 437 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1) AGE + demographics\n",
    "person_with_age = compute_age_vars(person_df)\n",
    "person_with_demo = add_age_sex_dummies(person_with_age)\n",
    "\n",
    "# 2) CC flags from diagnoses\n",
    "cc_flags_df = build_cc_flags(person_with_demo, diag_df, icd_cc_df)\n",
    "\n",
    "# 3) Apply hierarchies to get HCCs\n",
    "with_hcc = apply_hierarchy(person_with_demo, cc_flags_df)\n",
    "\n",
    "# 4) Compute 9 scores\n",
    "scored_df = compute_all_scores(with_hcc, coef_df)\n",
    "\n",
    "print(\"Shape after scoring:\", scored_df.shape)\n",
    "scored_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "d80da683",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBI</th>\n",
       "      <th>SEX</th>\n",
       "      <th>DOB</th>\n",
       "      <th>LTIMCAID</th>\n",
       "      <th>NEMCAID</th>\n",
       "      <th>OREC</th>\n",
       "      <th>AGEF</th>\n",
       "      <th>AGEF_EDIT</th>\n",
       "      <th>DISABL</th>\n",
       "      <th>ORIGDS</th>\n",
       "      <th>...</th>\n",
       "      <th>MCAID_ORIGDIS_NEM68</th>\n",
       "      <th>MCAID_ORIGDIS_NEM69</th>\n",
       "      <th>MCAID_ORIGDIS_NEM70_74</th>\n",
       "      <th>MCAID_ORIGDIS_NEM75_79</th>\n",
       "      <th>MCAID_ORIGDIS_NEM80_84</th>\n",
       "      <th>MCAID_ORIGDIS_NEM85_89</th>\n",
       "      <th>MCAID_ORIGDIS_NEM90_94</th>\n",
       "      <th>MCAID_ORIGDIS_NEM95_GT</th>\n",
       "      <th>SCORE_NEW_ENROLLEE</th>\n",
       "      <th>SCORE_SNP_NEW_ENROLLEE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>1</td>\n",
       "      <td>1950-06-15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>2</td>\n",
       "      <td>1980-03-10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>1</td>\n",
       "      <td>1965-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 437 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MBI SEX        DOB  LTIMCAID  NEMCAID OREC  AGEF  AGEF_EDIT  DISABL  \\\n",
       "0  P001   1 1950-06-15         1        0    0    75         75       0   \n",
       "1  P002   2 1980-03-10         0        1    1    45         45       1   \n",
       "2  P003   1 1965-12-01         0        0    0    60         60       0   \n",
       "\n",
       "   ORIGDS  ...  MCAID_ORIGDIS_NEM68  MCAID_ORIGDIS_NEM69  \\\n",
       "0       0  ...                  0.0                  0.0   \n",
       "1       0  ...                  0.0                  0.0   \n",
       "2       0  ...                  0.0                  0.0   \n",
       "\n",
       "   MCAID_ORIGDIS_NEM70_74  MCAID_ORIGDIS_NEM75_79  MCAID_ORIGDIS_NEM80_84  \\\n",
       "0                     0.0                     0.0                     0.0   \n",
       "1                     0.0                     0.0                     0.0   \n",
       "2                     0.0                     0.0                     0.0   \n",
       "\n",
       "   MCAID_ORIGDIS_NEM85_89  MCAID_ORIGDIS_NEM90_94  MCAID_ORIGDIS_NEM95_GT  \\\n",
       "0                     0.0                     0.0                     0.0   \n",
       "1                     0.0                     0.0                     0.0   \n",
       "2                     0.0                     0.0                     0.0   \n",
       "\n",
       "   SCORE_NEW_ENROLLEE  SCORE_SNP_NEW_ENROLLEE  \n",
       "0                 0.0                     0.0  \n",
       "1                 0.0                     0.0  \n",
       "2                 0.0                     0.0  \n",
       "\n",
       "[3 rows x 437 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scored_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1b7c2f32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (3, 304)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MBI</th>\n",
       "      <th>SEX</th>\n",
       "      <th>DOB</th>\n",
       "      <th>LTIMCAID</th>\n",
       "      <th>NEMCAID</th>\n",
       "      <th>OREC</th>\n",
       "      <th>AGEF</th>\n",
       "      <th>ORIGDS</th>\n",
       "      <th>DISABL</th>\n",
       "      <th>F0_34</th>\n",
       "      <th>...</th>\n",
       "      <th>CC463</th>\n",
       "      <th>SCORE_COMMUNITY_NA</th>\n",
       "      <th>SCORE_COMMUNITY_ND</th>\n",
       "      <th>SCORE_COMMUNITY_FBA</th>\n",
       "      <th>SCORE_COMMUNITY_FBD</th>\n",
       "      <th>SCORE_COMMUNITY_PBA</th>\n",
       "      <th>SCORE_COMMUNITY_PBD</th>\n",
       "      <th>SCORE_INSTITUTIONAL</th>\n",
       "      <th>SCORE_NEW_ENROLLEE</th>\n",
       "      <th>SCORE_SNP_NEW_ENROLLEE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>P001</td>\n",
       "      <td>1</td>\n",
       "      <td>1950-06-15</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>P002</td>\n",
       "      <td>2</td>\n",
       "      <td>1980-03-10</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.340</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>P003</td>\n",
       "      <td>1</td>\n",
       "      <td>1965-12-01</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.345</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 304 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    MBI SEX        DOB  LTIMCAID  NEMCAID OREC  AGEF  ORIGDS  DISABL  F0_34  \\\n",
       "0  P001   1 1950-06-15         1        0    0    75       0       0      0   \n",
       "1  P002   2 1980-03-10         0        1    1    45       0       1      0   \n",
       "2  P003   1 1965-12-01         0        0    0    60       0       0      0   \n",
       "\n",
       "   ...  CC463  SCORE_COMMUNITY_NA  SCORE_COMMUNITY_ND  SCORE_COMMUNITY_FBA  \\\n",
       "0  ...      0               0.502               0.000                  0.0   \n",
       "1  ...      0               0.000               0.340                  0.0   \n",
       "2  ...      0               0.000               0.345                  0.0   \n",
       "\n",
       "   SCORE_COMMUNITY_FBD  SCORE_COMMUNITY_PBA  SCORE_COMMUNITY_PBD  \\\n",
       "0                  0.0                  0.0                  0.0   \n",
       "1                  0.0                  0.0                  0.0   \n",
       "2                  0.0                  0.0                  0.0   \n",
       "\n",
       "   SCORE_INSTITUTIONAL  SCORE_NEW_ENROLLEE  SCORE_SNP_NEW_ENROLLEE  \n",
       "0                  0.0                 0.0                     0.0  \n",
       "1                  0.0                 0.0                     0.0  \n",
       "2                  0.0                 0.0                     0.0  \n",
       "\n",
       "[3 rows x 304 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5) Apply KEEP list equivalent to SAS V2825T2P and save CSV [file:38][file:31]\n",
    "\n",
    "keepvars = [\n",
    "    ID_COL,\n",
    "    \"SEX\", \"DOB\", \"LTIMCAID\", \"NEMCAID\", \"OREC\",\n",
    "    *DEM_VARS,\n",
    "    *HCC_LIST,\n",
    "    *CC_LIST,\n",
    "    \"SCORE_COMMUNITY_NA\",\n",
    "    \"SCORE_COMMUNITY_ND\",\n",
    "    \"SCORE_COMMUNITY_FBA\",\n",
    "    \"SCORE_COMMUNITY_FBD\",\n",
    "    \"SCORE_COMMUNITY_PBA\",\n",
    "    \"SCORE_COMMUNITY_PBD\",\n",
    "    \"SCORE_INSTITUTIONAL\",\n",
    "    \"SCORE_NEW_ENROLLEE\",\n",
    "    \"SCORE_SNP_NEW_ENROLLEE\",\n",
    "]\n",
    "\n",
    "existing_keep = [c for c in keepvars if c in scored_df.columns]\n",
    "final_df = scored_df[existing_keep].copy()\n",
    "print(\"Final shape:\", final_df.shape)\n",
    "final_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a37d91bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_final_score(row):\n",
    "    # AGEF is the SAS age variable carried through your code\n",
    "    age = row[\"AGEF\"]\n",
    "    orec = str(row[\"OREC\"])\n",
    "    ltimcaid = row[\"LTIMCAID\"]\n",
    "    nemcaid = row[\"NEMCAID\"]\n",
    "\n",
    "    # --- Status flags (adjust to your data) ---\n",
    "    # New Enrollee vs continuing (you may have a dedicated NE flag; NEMCAID is a proxy here)\n",
    "    is_ne = nemcaid > 0\n",
    "\n",
    "    # Institutional vs community\n",
    "    is_inst = ltimcaid == 1\n",
    "\n",
    "    # Aged vs disabled (CMS convention: originally disabled if OREC='1')\n",
    "    is_aged = (age >= 65) and (orec != \"1\")\n",
    "    is_disabled = (age < 65) or (orec == \"1\")\n",
    "\n",
    "    # Dual status flags – plug in your own columns\n",
    "    is_full_dual = row.get(\"FULL_DUAL\", 0) == 1\n",
    "    is_partial_dual = row.get(\"PART_DUAL\", 0) == 1\n",
    "    is_non_dual = not (is_full_dual or is_partial_dual)\n",
    "\n",
    "    # SNP flag – adjust to your column name\n",
    "    is_snp = row.get(\"SNP\", 0) == 1\n",
    "\n",
    "    # --- Score choice logic ---\n",
    "    if is_ne:\n",
    "        if is_snp:\n",
    "            return row[\"SCORE_SNP_NEW_ENROLLEE\"]\n",
    "        else:\n",
    "            return row[\"SCORE_NEW_ENROLLEE\"]\n",
    "\n",
    "    if is_inst:\n",
    "        return row[\"SCORE_INSTITUTIONAL\"]\n",
    "\n",
    "    if is_non_dual and is_aged:\n",
    "        return row[\"SCORE_COMMUNITY_NA\"]\n",
    "    if is_non_dual and is_disabled:\n",
    "        return row[\"SCORE_COMMUNITY_ND\"]\n",
    "    if is_full_dual and is_aged:\n",
    "        return row[\"SCORE_COMMUNITY_FBA\"]\n",
    "    if is_full_dual and is_disabled:\n",
    "        return row[\"SCORE_COMMUNITY_FBD\"]\n",
    "    if is_partial_dual and is_aged:\n",
    "        return row[\"SCORE_COMMUNITY_PBA\"]\n",
    "    if is_partial_dual and is_disabled:\n",
    "        return row[\"SCORE_COMMUNITY_PBD\"]\n",
    "\n",
    "    return 0.0\n",
    "\n",
    "final_df[\"FINAL_SCORE\"] = scored_df.apply(choose_final_score, axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1572e22",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'final_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# 6) Write CSV output\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mfinal_df\u001b[49m.to_csv(output_path, index=\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m      3\u001b[39m output_path\n",
      "\u001b[31mNameError\u001b[39m: name 'final_df' is not defined"
     ]
    }
   ],
   "source": [
    "# 6) Write CSV output\n",
    "final_df.to_csv(output_path, index=False)\n",
    "output_path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cbdb0694",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wrote: cms_v28_hcc_scores_with_final.csv\n"
     ]
    }
   ],
   "source": [
    "output_path = \"cms_v28_hcc_scores_with_final.csv\"\n",
    "final_df.to_csv(output_path, index=False)\n",
    "print(\"Wrote:\", output_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "59290acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.gitignore',\n",
       " '.ipynb_checkpoints',\n",
       " 'CMS-HCC V28.ipynb',\n",
       " 'cms_v28_hcc_scores_with_final.csv',\n",
       " 'data',\n",
       " 'etc',\n",
       " 'Include',\n",
       " 'Lib',\n",
       " 'pyvenv.cfg',\n",
       " 'Scripts',\n",
       " 'share']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()          # shows the folder\n",
    "os.listdir()         # should list \"cms_v28_hcc_scores_with_final.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c780e51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.13 (py313_env)",
   "language": "python",
   "name": "py313_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
